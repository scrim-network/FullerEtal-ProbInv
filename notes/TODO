read
    Roe & Baker - climate sensitivity, science
        gaussian prior in parameter
            Urban and Keller 2009 write about how this is stupid
                is this the Tellus paper?

    Tellus paper.  find joint distribution of parameters
        normal priors are stupid?  (see above)

    Oppenheimer paper
        MCMC PI

    RDM
        snakes?
            Garner, Reed, Keller 2016, last figure, DICE snake

Klaus orders
    1 page summary:  title, 1 sentence summary, 3 key points, authors, nat/sci paragraph, sketch figures
        points
            1. Pfeffer - physical limit - how fast can ice flow - 2 bounds - uncertainty
            2. Paleo record - Tony needs prior - helps inform prior
            3. expert assessment - likelihood funciton - physically motivated priors

    use rejection sampling to post process posterior
        Tierney 1994 is the reference

        we have the log likelihood chain
            can produce the density from this using exp(llik)
                but the density is the same for all samples

        better to use bkde
            fix up y like fixing up llik
                need to record adapt flag in assimctx

            approxfun will do linear interpolation with the return of bkde
                x <- log(rgamma(150,5))
                df <- approxfun(density(x))
                plot(density(x))
                xnew <- c(0.45,1.84,2.3)
                points(xnew,df(xnew),col=2)

                sampled <- data.frame(proposal = runif(100000,0,1))
                sampled$targetDensity <- dbeta(sampled$proposal, 3,6)

                Now, accept proportional to the targetDensity. Itâ€™s easiest if we calculate the highest density value, and then accept the others in relation to that

                maxDens = max(sampled$targetDensity, na.rm = T)
                sampled$accepted = ifelse(runif(100000,0,1) < sampled$targetDensity / maxDens, TRUE, FALSE)

                Plot the result

                hist(sampled$proposal[sampled$accepted], freq = F, col = "grey", breaks = 100)
                curve(dbeta(x, 3,6),0,1, add =T, col = "red")

    3 prior plot with 90% contour (10% contour)
        dot at highest density

    6 panel PDF/CDF for comparing exp assess only to all data

    figures
        source('makefig.R'); figAisPriors(); figCmpPriors(); figPredict(); figUber(); figCmpInst()

code
    add chain diagnostic code from Kelsey and Tony
        Gelman & Rubin stats
            below 1.1 or 1.05, then converged

            as a function of iterations
                    500K converged

            for two chains

    Latin hypercube
        where are NaNs
            what does it say about physical relationships?

    noise realization
        look at paper and code

        bootstrap the residuals?
            how do we do this with an MCMC chain?

    look at constraints
        try DeConto and Pollard
            look at their paper and Kelsey's treatment
                see Slack convo

    start from LIG?

    look at LHS and priors from Tony assimilation code
        Tony assim does not run.  missing Tg, anto.a, and anto.b

    more predictions
        autocorrelation -- LAG -- minimum LAG -- ACF -- superimpose
            when flattened, not enough predictions?

compare code
    rsync -n --stats -hh -v -H -x -a --delete-after --exclude Scratch/ woju.scrim.psu.edu:/woju/s0/klr324/Ruckertetal_DAIS_codes/ ~/cRucker/
    diff -br --exclude \*pdf --exclude \*csv --exclude \*jpeg --exclude \*mat --exclude \*RData --exclude \*tif ruckert_dais ~/cRucker

    rsync -n --stats -hh -v -H -x -a --delete-after --exclude Random_out/ --exclude Workspace --exclude DAIS_matlab/OtimizedInitialParameters.csv --exclude DAIS_matlab/old_DataCode_versions/DAIS_Matlab_MCMCcalibration.mat --exclude old_code_attempts/dais_error.txt --exclude .git/ woju.scrim.psu.edu:/woju/s0/klr324/Ruckertetal_DAIS_codes ~/Ruckertetal_DAIS_codes.ORIG
